#### This layouts the (summarized) topics of Deep Learning Nanodegree at [Udacity](https://github.com/udacity) and my progress.

* Environment: Python3, Jupyter Notebook, Anaconda, Mac OS Catalina 10.15.x

## Exercise
[Exercise 01: Neural Networks > Gradient Descent Algorithm](https://github.com/yoonseopark001/Deep-Learning-Udacity/blob/master/L1E1_Neural%20Networks_GradientDescent.ipynb)

## 0. Introduction to Deep Learning
* 1-4. Program Introduction `Day 1`
* 5-7. Managing Environment `Day 2`
     * Examples: Style Transfer, DeepTraffic, Flappy Bird
## 1. Matrix Math and NumPy Refresher 
 1. Data Dimensions
 2. Data in NumPy 
 3. Element-wise Matrix Operations
 4. Element-wise Operations in NumPy   
 5. Matrix Multiplication  
 6. NumPy Matrix Multiplication  `Day 3`
 7. Matrix Transposes
 8. Transposes in NumPy 

## 2. Neural Networks
### 1. Introduction to Neural Networks
 1. Classification Problems
 2. Linear Boundaries
 3. Higher Dimensions // `Day 4`
 4. Perceptrons
 5. Why "Neural Networks"?
 6. Perceptrons as Logical Operators
 7. Perceptron Trick
 8. Perceptron Algorithm // `Day 5`
 9. Non-Linear Regions
 10. Error Functions
 11. Log-loss Error Function
 12. Discrete vs Continuous: sigmoid
 13. Softmax
 14. One-Hot Encoding
 15. Maximum Likelihood
 16. Maximizing Probabilities // `Day 6`
 17. Cross-Entropy
 18. Multi-Class Cross Entropy
 19. Logistic Regression
 20. Gradient Descent
 21. Logistic Regression Algorithm // `Day 7` 
 [Exercise 01: Neural Networks > Gradient Descent Algorithm](https://github.com/yoonseopark001/Deep-Learning-Udacity/blob/master/L1E1_Neural%20Networks_GradientDescent.ipynb)
 23. Perceptron vs Gradient Descent
 24. Continuous Perceptrons
 25. Non-linear Data
 26. Non-Linear Models
 27. Neural Network Architecture
 28. Feedforward
 29. Backpropagation
 30. Analyzing Student Data


* Book: Grokking Deep Learning by Andrew Trask
* [Practice and exercises](https://github.com/udacity/deep-learning-v2-pytorch)
